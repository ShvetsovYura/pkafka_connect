===> User
uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
===> Configuring ...
===> Running preflight checks ... 
===> Check if Kafka is healthy ...
Using log4j config /etc/cp-base-new/log4j.properties
===> Launching ... 
===> Launching kafka-connect ... 
[2025-02-10 17:17:50,226] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli)
[2025-02-10 17:17:50,229] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Djava.rmi.server.hostname=172.19.0.4, -Dcom.sun.management.jmxremote.local.only=false, -Dcom.sun.management.jmxremote.rmi.port=9875, -Dcom.sun.management.jmxremote.port=9875, -Dcom.sun.management.jmxremote.port=9875, -Dkafka.logs.dir=/var/log/kafka, -Dlog4j.configuration=file:/etc/kafka/connect-log4j.properties, -javaagent:/opt/jmx_prometheus_javaagent-0.15.0.jar=9876:/opt/kafka-connect.yml
	jvm.spec = Azul Systems, Inc., OpenJDK 64-Bit Server VM, 17.0.12, 17.0.12+7-LTS
	jvm.classpath = /etc/kafka-connect/jars/*:/usr/share/java/kafka/netty-common-4.1.110.Final.jar:/usr/share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/share/java/kafka/jline-3.25.1.jar:/usr/share/java/kafka/connect-json-7.7.1-ccs.jar:/usr/share/java/kafka/netty-transport-native-epoll-4.1.110.Final.jar:/usr/share/java/kafka/kafka-server-common-7.7.1-ccs.jar:/usr/share/java/kafka/netty-handler-4.1.110.Final.jar:/usr/share/java/kafka/jetty-servlet-9.4.54.v20240208.jar:/usr/share/java/kafka/jackson-jaxrs-base-2.16.2.jar:/usr/share/java/kafka/kafka.jar:/usr/share/java/kafka/paranamer-2.8.jar:/usr/share/java/kafka/swagger-annotations-2.2.8.jar:/usr/share/java/kafka/hk2-utils-2.6.1.jar:/usr/share/java/kafka/jersey-common-2.39.1.jar:/usr/share/java/kafka/kafka-server-7.7.1-ccs.jar:/usr/share/java/kafka/zstd-jni-1.5.6-4.jar:/usr/share/java/kafka/zookeeper-jute-3.8.4.jar:/usr/share/java/kafka/jackson-databind-2.16.2.jar:/usr/share/java/kafka/kafka-storage-api-7.7.1-ccs.jar:/usr/share/java/kafka/connect-mirror-7.7.1-ccs.jar:/usr/share/java/kafka/commons-lang3-3.8.1.jar:/usr/share/java/kafka/commons-beanutils-1.9.4.jar:/usr/share/java/kafka/commons-validator-1.7.jar:/usr/share/java/kafka/jackson-core-2.16.2.jar:/usr/share/java/kafka/netty-resolver-4.1.110.Final.jar:/usr/share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/share/java/kafka/jersey-server-2.39.1.jar:/usr/share/java/kafka/jetty-util-ajax-9.4.54.v20240208.jar:/usr/share/java/kafka/connect-mirror-client-7.7.1-ccs.jar:/usr/share/java/kafka/argparse4j-0.7.0.jar:/usr/share/java/kafka/kafka-streams-test-utils-7.7.1-ccs.jar:/usr/share/java/kafka/commons-digester-2.1.jar:/usr/share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/share/java/kafka/metrics-core-4.1.12.1.jar:/usr/share/java/kafka/kafka-streams-scala_2.13-7.7.1-ccs.jar:/usr/share/java/kafka/jetty-security-9.4.54.v20240208.jar:/usr/share/java/kafka/jsr305-3.0.2.jar:/usr/share/java/kafka/kafka-tools-7.7.1-ccs.jar:/usr/share/java/kafka/kafka-raft-7.7.1-ccs.jar:/usr/share/java/kafka/audience-annotations-0.12.0.jar:/usr/share/java/kafka/jackson-module-scala_2.13-2.16.2.jar:/usr/share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/share/java/kafka/kafka-log4j-appender-7.7.1-ccs.jar:/usr/share/java/kafka/protobuf-java-3.23.4.jar:/usr/share/java/kafka/kafka-storage-7.7.1-ccs.jar:/usr/share/java/kafka/jackson-jaxrs-json-provider-2.16.2.jar:/usr/share/java/kafka/reload4j-1.2.25.jar:/usr/share/java/kafka/connect-runtime-7.7.1-ccs.jar:/usr/share/java/kafka/kafka-clients-7.7.1-ccs.jar:/usr/share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/share/java/kafka/hk2-api-2.6.1.jar:/usr/share/java/kafka/kafka-group-coordinator-7.7.1-ccs.jar:/usr/share/java/kafka/jackson-datatype-jdk8-2.16.2.jar:/usr/share/java/kafka/connect-basic-auth-extension-7.7.1-ccs.jar:/usr/share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/share/java/kafka/jopt-simple-5.0.4.jar:/usr/share/java/kafka/hk2-locator-2.6.1.jar:/usr/share/java/kafka/jackson-module-jaxb-annotations-2.16.2.jar:/usr/share/java/kafka/jackson-annotations-2.16.2.jar:/usr/share/java/kafka/connect-api-7.7.1-ccs.jar:/usr/share/java/kafka/kafka-streams-7.7.1-ccs.jar:/usr/share/java/kafka/metrics-core-2.2.0.jar:/usr/share/java/kafka/jaxb-api-2.3.1.jar:/usr/share/java/kafka/pcollections-4.0.1.jar:/usr/share/java/kafka/jetty-client-9.4.54.v20240208.jar:/usr/share/java/kafka/commons-logging-1.2.jar:/usr/share/java/kafka/lz4-java-1.8.0.jar:/usr/share/java/kafka/error_prone_annotations-2.10.0.jar:/usr/share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/share/java/kafka/slf4j-api-1.7.36.jar:/usr/share/java/kafka/jetty-server-9.4.54.v20240208.jar:/usr/share/java/kafka/maven-artifact-3.8.8.jar:/usr/share/java/kafka/caffeine-2.9.3.jar:/usr/share/java/kafka/javax.activation-api-1.2.0.jar:/usr/share/java/kafka/jersey-client-2.39.1.jar:/usr/share/java/kafka/checker-qual-3.19.0.jar:/usr/share/java/kafka/jakarta.inject-2.6.1.jar:/usr/share/java/kafka/scala-library-2.13.12.jar:/usr/share/java/kafka/netty-codec-4.1.110.Final.jar:/usr/share/java/kafka/jetty-http-9.4.54.v20240208.jar:/usr/share/java/kafka/connect-transforms-7.7.1-ccs.jar:/usr/share/java/kafka/netty-transport-4.1.110.Final.jar:/usr/share/java/kafka/netty-transport-classes-epoll-4.1.110.Final.jar:/usr/share/java/kafka/netty-transport-native-unix-common-4.1.110.Final.jar:/usr/share/java/kafka/kafka-streams-examples-7.7.1-ccs.jar:/usr/share/java/kafka/jetty-servlets-9.4.54.v20240208.jar:/usr/share/java/kafka/jetty-util-9.4.54.v20240208.jar:/usr/share/java/kafka/jackson-dataformat-csv-2.16.2.jar:/usr/share/java/kafka/zookeeper-3.8.4.jar:/usr/share/java/kafka/rocksdbjni-7.9.2.jar:/usr/share/java/kafka/kafka-shell-7.7.1-ccs.jar:/usr/share/java/kafka/kafka-metadata-7.7.1-ccs.jar:/usr/share/java/kafka/jetty-continuation-9.4.54.v20240208.jar:/usr/share/java/kafka/kafka-tools-api-7.7.1-ccs.jar:/usr/share/java/kafka/jersey-hk2-2.39.1.jar:/usr/share/java/kafka/javassist-3.29.2-GA.jar:/usr/share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/share/java/kafka/jetty-io-9.4.54.v20240208.jar:/usr/share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/share/java/kafka/plexus-utils-3.3.1.jar:/usr/share/java/kafka/reflections-0.10.2.jar:/usr/share/java/kafka/opentelemetry-proto-1.0.0-alpha.jar:/usr/share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/share/java/kafka/commons-io-2.11.0.jar:/usr/share/java/kafka/commons-collections-3.2.2.jar:/usr/share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/share/java/kafka/activation-1.1.1.jar:/usr/share/java/kafka/kafka_2.13-7.7.1-ccs.jar:/usr/share/java/kafka/jose4j-0.9.4.jar:/usr/share/java/kafka/trogdor-7.7.1-ccs.jar:/usr/share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/share/java/kafka/snappy-java-1.1.10.5.jar:/usr/share/java/kafka/scala-reflect-2.13.12.jar:/usr/share/java/kafka/commons-cli-1.4.jar:/usr/share/java/kafka/netty-buffer-4.1.110.Final.jar:/usr/share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/confluent-common/common-config-7.7.1.jar:/usr/share/java/confluent-common/slf4j-api-1.7.36.jar:/usr/share/java/confluent-common/common-utils-7.7.1.jar:/usr/share/java/confluent-common/build-tools-7.7.1.jar:/usr/share/java/confluent-common/common-metrics-7.7.1.jar:/usr/share/java/kafka-serde-tools/commons-lang3-3.12.0.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-protobuf-2.16.0.jar:/usr/share/java/kafka-serde-tools/everit-json-schema-1.14.3.jar:/usr/share/java/kafka-serde-tools/protobuf-java-3.25.4.jar:/usr/share/java/kafka-serde-tools/kotlin-stdlib-common-1.9.10.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-tink-7.7.1.jar:/usr/share/java/kafka-serde-tools/netty-common-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/netty-resolver-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/protoparser-4.0.3.jar:/usr/share/java/kafka-serde-tools/cel-jackson-0.3.12.jar:/usr/share/java/kafka-serde-tools/auto-value-annotations-1.9.jar:/usr/share/java/kafka-serde-tools/netty-codec-http2-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/reactive-streams-1.0.4.jar:/usr/share/java/kafka-serde-tools/kotlin-reflect-1.9.22.jar:/usr/share/java/kafka-serde-tools/google-api-services-cloudkms-v1-rev20221107-2.0.0.jar:/usr/share/java/kafka-serde-tools/woodstox-core-6.5.1.jar:/usr/share/java/kafka-serde-tools/jackson-annotations-2.16.0.jar:/usr/share/java/kafka-serde-tools/kotlin-scripting-compiler-embeddable-1.9.10.jar:/usr/share/java/kafka-serde-tools/netty-resolver-dns-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/netty-codec-dns-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/json-sKema-0.15.0.jar:/usr/share/java/kafka-serde-tools/azure-security-keyvault-keys-4.6.1.jar:/usr/share/java/kafka-serde-tools/commons-beanutils-1.9.4.jar:/usr/share/java/kafka-serde-tools/commons-validator-1.7.jar:/usr/share/java/kafka-serde-tools/kotlin-stdlib-1.9.10.jar:/usr/share/java/kafka-serde-tools/kafka-connect-avro-data-7.7.1.jar:/usr/share/java/kafka-serde-tools/kafka-json-schema-serializer-7.7.1.jar:/usr/share/java/kafka-serde-tools/mbknor-jackson-jsonschema_2.13-1.0.39.jar:/usr/share/java/kafka-serde-tools/okio-jvm-3.4.0.jar:/usr/share/java/kafka-serde-tools/google-api-client-1.35.2.jar:/usr/share/java/kafka-serde-tools/annotations-13.0.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-yaml-2.16.0.jar:/usr/share/java/kafka-serde-tools/tink-gcpkms-1.9.0.jar:/usr/share/java/kafka-serde-tools/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/share/java/kafka-serde-tools/jackson-module-parameter-names-2.16.0.jar:/usr/share/java/kafka-serde-tools/logredactor-1.0.12.jar:/usr/share/java/kafka-serde-tools/commons-digester-2.1.jar:/usr/share/java/kafka-serde-tools/minimal-json-0.9.5.jar:/usr/share/java/kafka-serde-tools/content-type-2.3.jar:/usr/share/java/kafka-serde-tools/antlr4-runtime-4.13.1.jar:/usr/share/java/kafka-serde-tools/netty-transport-native-kqueue-4.1.108.Final-osx-x86_64.jar:/usr/share/java/kafka-serde-tools/netty-buffer-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/kotlin-scripting-common-1.9.10.jar:/usr/share/java/kafka-serde-tools/grpc-context-1.27.2.jar:/usr/share/java/kafka-serde-tools/azure-xml-1.0.0.jar:/usr/share/java/kafka-serde-tools/opencensus-api-0.31.1.jar:/usr/share/java/kafka-serde-tools/reactor-netty-core-1.0.43.jar:/usr/share/java/kafka-serde-tools/kotlinpoet-jvm-1.16.0.jar:/usr/share/java/kafka-serde-tools/handy-uri-templates-2.1.8.jar:/usr/share/java/kafka-serde-tools/jsr305-3.0.2.jar:/usr/share/java/kafka-serde-tools/accessors-smart-2.5.0.jar:/usr/share/java/kafka-serde-tools/jackson-core-2.16.0.jar:/usr/share/java/kafka-serde-tools/google-http-client-gson-1.43.1.jar:/usr/share/java/kafka-serde-tools/jna-platform-5.6.0.jar:/usr/share/java/kafka-serde-tools/jcip-annotations-1.0-1.jar:/usr/share/java/kafka-serde-tools/netty-transport-native-epoll-4.1.108.Final-linux-x86_64.jar:/usr/share/java/kafka-serde-tools/scala-library-2.13.10.jar:/usr/share/java/kafka-serde-tools/kafka-schema-serializer-7.7.1.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-protobuf-0.9.13.jar:/usr/share/java/kafka-serde-tools/json-20231013.jar:/usr/share/java/kafka-serde-tools/lang-tag-1.7.jar:/usr/share/java/kafka-serde-tools/tink-1.12.0.jar:/usr/share/java/kafka-serde-tools/commons-io-2.15.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-7.7.1.jar:/usr/share/java/kafka-serde-tools/kotlin-stdlib-jdk7-1.9.10.jar:/usr/share/java/kafka-serde-tools/error_prone_annotations-2.18.0.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-xml-2.16.0.jar:/usr/share/java/kafka-serde-tools/annotations-3.0.1.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-guava-2.16.0.jar:/usr/share/java/kafka-serde-tools/google-auth-library-credentials-1.5.3.jar:/usr/share/java/kafka-serde-tools/JSONata4Java-2.4.5.jar:/usr/share/java/kafka-serde-tools/netty-resolver-dns-native-macos-4.1.108.Final-osx-x86_64.jar:/usr/share/java/kafka-serde-tools/jackson-databind-2.16.0.jar:/usr/share/java/kafka-serde-tools/azure-identity-1.12.1.jar:/usr/share/java/kafka-serde-tools/json-smart-2.5.0.jar:/usr/share/java/kafka-serde-tools/swagger-annotations-2.1.10.jar:/usr/share/java/kafka-serde-tools/kafka-json-schema-provider-7.7.1.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.65.Final.jar:/usr/share/java/kafka-serde-tools/kafka-connect-protobuf-converter-7.7.1.jar:/usr/share/java/kafka-serde-tools/kafka-streams-json-schema-serde-7.7.1.jar:/usr/share/java/kafka-serde-tools/re2j-1.6.jar:/usr/share/java/kafka-serde-tools/google-http-client-apache-v2-1.42.0.jar:/usr/share/java/kafka-serde-tools/azure-json-1.1.0.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-7.7.1.jar:/usr/share/java/kafka-serde-tools/netty-transport-native-unix-common-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/kafka-avro-serializer-7.7.1.jar:/usr/share/java/kafka-serde-tools/snakeyaml-2.0.jar:/usr/share/java/kafka-serde-tools/kafka-streams-7.7.1-ccs.jar:/usr/share/java/kafka-serde-tools/reactor-core-3.4.36.jar:/usr/share/java/kafka-serde-tools/netty-codec-http-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/kafka-connect-json-schema-converter-7.7.1.jar:/usr/share/java/kafka-serde-tools/kotlin-script-runtime-1.9.10.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-gcp-7.7.1.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-classes-2.0.65.Final.jar:/usr/share/java/kafka-serde-tools/stax2-api-4.2.1.jar:/usr/share/java/kafka-serde-tools/netty-codec-socks-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/httpclient-4.5.13.jar:/usr/share/java/kafka-serde-tools/nimbus-jose-jwt-9.37.3.jar:/usr/share/java/kafka-serde-tools/netty-codec-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/aws-java-sdk-kms-1.12.701.jar:/usr/share/java/kafka-serde-tools/commons-logging-1.2.jar:/usr/share/java/kafka-serde-tools/gson-2.9.0.jar:/usr/share/java/kafka-serde-tools/cel-core-0.3.12.jar:/usr/share/java/kafka-serde-tools/google-oauth-client-1.34.1.jar:/usr/share/java/kafka-serde-tools/auto-service-annotations-1.0.1.jar:/usr/share/java/kafka-serde-tools/proto-google-common-protos-2.22.1.jar:/usr/share/java/kafka-serde-tools/kafka-streams-protobuf-serde-7.7.1.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.65.Final-osx-x86_64.jar:/usr/share/java/kafka-serde-tools/cel-tools-0.3.12.jar:/usr/share/java/kafka-serde-tools/netty-resolver-dns-classes-macos-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.65.Final-windows-x86_64.jar:/usr/share/java/kafka-serde-tools/google-auth-library-oauth2-http-1.5.3.jar:/usr/share/java/kafka-serde-tools/google-http-client-1.43.1.jar:/usr/share/java/kafka-serde-tools/jmespath-java-1.12.701.jar:/usr/share/java/kafka-serde-tools/slf4j-api-1.7.36.jar:/usr/share/java/kafka-serde-tools/failureaccess-1.0.1.jar:/usr/share/java/kafka-serde-tools/joda-time-2.10.14.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.65.Final-linux-aarch_64.jar:/usr/share/java/kafka-serde-tools/msal4j-persistence-extension-1.3.0.jar:/usr/share/java/kafka-serde-tools/kafka-connect-avro-converter-7.7.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-azure-7.7.1.jar:/usr/share/java/kafka-serde-tools/azure-core-http-netty-1.15.0.jar:/usr/share/java/kafka-serde-tools/netty-transport-classes-epoll-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/netty-handler-proxy-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/kotlin-scripting-compiler-impl-embeddable-1.9.10.jar:/usr/share/java/kafka-serde-tools/httpcore-4.4.15.jar:/usr/share/java/kafka-serde-tools/tink-awskms-1.9.1.jar:/usr/share/java/kafka-serde-tools/picocli-4.7.5.jar:/usr/share/java/kafka-serde-tools/netty-handler-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/kafka-streams-avro-serde-7.7.1.jar:/usr/share/java/kafka-serde-tools/kotlin-stdlib-jdk8-1.9.10.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.65.Final-linux-x86_64.jar:/usr/share/java/kafka-serde-tools/vault-java-driver-5.4.0.jar:/usr/share/java/kafka-serde-tools/kafka-schema-converter-7.7.1.jar:/usr/share/java/kafka-serde-tools/kafka-protobuf-types-7.7.1.jar:/usr/share/java/kafka-serde-tools/jna-5.13.0.jar:/usr/share/java/kafka-serde-tools/classgraph-4.8.138.jar:/usr/share/java/kafka-serde-tools/rocksdbjni-7.9.2.jar:/usr/share/java/kafka-serde-tools/kafka-schema-rules-7.7.1.jar:/usr/share/java/kafka-serde-tools/msal4j-1.15.0.jar:/usr/share/java/kafka-serde-tools/avro-1.11.3.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-csv-2.16.0.jar:/usr/share/java/kafka-serde-tools/cel-generated-antlr-0.3.12.jar:/usr/share/java/kafka-serde-tools/kafka-protobuf-serializer-7.7.1.jar:/usr/share/java/kafka-serde-tools/commons-codec-1.16.1.jar:/usr/share/java/kafka-serde-tools/netty-transport-classes-kqueue-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/checker-qual-3.33.0.jar:/usr/share/java/kafka-serde-tools/kafka-json-serializer-7.7.1.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-jsr310-2.16.0.jar:/usr/share/java/kafka-serde-tools/wire-runtime-jvm-4.9.7.jar:/usr/share/java/kafka-serde-tools/aws-java-sdk-core-1.12.701.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-joda-2.16.0.jar:/usr/share/java/kafka-serde-tools/wire-schema-jvm-4.9.7.jar:/usr/share/java/kafka-serde-tools/netty-transport-4.1.108.Final.jar:/usr/share/java/kafka-serde-tools/cel-generated-pb-0.3.12.jar:/usr/share/java/kafka-serde-tools/dek-registry-client-7.7.1.jar:/usr/share/java/kafka-serde-tools/azure-core-1.49.0.jar:/usr/share/java/kafka-serde-tools/oauth2-oidc-sdk-11.9.1.jar:/usr/share/java/kafka-serde-tools/commons-collections-3.2.2.jar:/usr/share/java/kafka-serde-tools/asm-9.3.jar:/usr/share/java/kafka-serde-tools/j2objc-annotations-2.8.jar:/usr/share/java/kafka-serde-tools/protobuf-java-util-3.25.4.jar:/usr/share/java/kafka-serde-tools/javapoet-1.13.0.jar:/usr/share/java/kafka-serde-tools/jackson-datatype-jdk8-2.16.0.jar:/usr/share/java/kafka-serde-tools/commons-text-1.10.0.jar:/usr/share/java/kafka-serde-tools/agrona-1.17.1.jar:/usr/share/java/kafka-serde-tools/kafka-protobuf-provider-7.7.1.jar:/usr/share/java/kafka-serde-tools/logredactor-metrics-1.0.12.jar:/usr/share/java/kafka-serde-tools/reactor-netty-http-1.0.43.jar:/usr/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.65.Final-osx-aarch_64.jar:/usr/share/java/kafka-serde-tools/opencensus-contrib-http-util-0.31.1.jar:/usr/share/java/kafka-serde-tools/commons-compress-1.26.1.jar:/usr/share/java/kafka-serde-tools/validation-api-2.0.1.Final.jar:/usr/share/java/kafka-serde-tools/guava-32.0.1-jre.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-hcvault-7.7.1.jar:/usr/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-aws-7.7.1.jar:/usr/share/java/kafka-serde-tools/kotlin-scripting-jvm-1.9.10.jar:/usr/share/java/kafka-serde-tools/jackson-dataformat-cbor-2.16.0.jar:/usr/share/java/monitoring-interceptors/monitoring-interceptors-7.7.1.jar:/usr/bin/../share/java/kafka/netty-common-4.1.110.Final.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jline-3.25.1.jar:/usr/bin/../share/java/kafka/connect-json-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.110.Final.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.110.Final.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.16.2.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/jersey-common-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-server-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.6-4.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.8.4.jar:/usr/bin/../share/java/kafka/jackson-databind-2.16.2.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/commons-beanutils-1.9.4.jar:/usr/bin/../share/java/kafka/commons-validator-1.7.jar:/usr/bin/../share/java/kafka/jackson-core-2.16.2.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.110.Final.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/jersey-server-2.39.1.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/commons-digester-2.1.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/jsr305-3.0.2.jar:/usr/bin/../share/java/kafka/kafka-tools-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-raft-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/audience-annotations-0.12.0.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.16.2.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/protobuf-java-3.23.4.jar:/usr/bin/../share/java/kafka/kafka-storage-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.16.2.jar:/usr/bin/../share/java/kafka/reload4j-1.2.25.jar:/usr/bin/../share/java/kafka/connect-runtime-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-clients-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.16.2.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.16.2.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.16.2.jar:/usr/bin/../share/java/kafka/connect-api-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-streams-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.1.jar:/usr/bin/../share/java/kafka/pcollections-4.0.1.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/commons-logging-1.2.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/error_prone_annotations-2.10.0.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.8.jar:/usr/bin/../share/java/kafka/caffeine-2.9.3.jar:/usr/bin/../share/java/kafka/javax.activation-api-1.2.0.jar:/usr/bin/../share/java/kafka/jersey-client-2.39.1.jar:/usr/bin/../share/java/kafka/checker-qual-3.19.0.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/scala-library-2.13.12.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.110.Final.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/connect-transforms-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.110.Final.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.110.Final.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.110.Final.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.16.2.jar:/usr/bin/../share/java/kafka/zookeeper-3.8.4.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.9.2.jar:/usr/bin/../share/java/kafka/kafka-shell-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/kafka-tools-api-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/usr/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.54.v20240208.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.1.jar:/usr/bin/../share/java/kafka/reflections-0.10.2.jar:/usr/bin/../share/java/kafka/opentelemetry-proto-1.0.0-alpha.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/usr/bin/../share/java/kafka/commons-io-2.11.0.jar:/usr/bin/../share/java/kafka/commons-collections-3.2.2.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/jose4j-0.9.4.jar:/usr/bin/../share/java/kafka/trogdor-7.7.1-ccs.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.10.5.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.12.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.110.Final.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/confluent-telemetry/confluent-metrics-7.7.1-ce.jar
	os.spec = Linux, amd64, 6.8.0-52-generic
	os.vcpus = 2
 (org.apache.kafka.connect.runtime.WorkerInfo)
[2025-02-10 17:17:50,232] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli)
[2025-02-10 17:17:50,466] INFO Loading plugin from: /usr/share/java/cp-base-new (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:51,598] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/cp-base-new/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:51,605] INFO Loading plugin from: /usr/share/java/acl (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:52,395] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/acl/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:52,396] INFO Loading plugin from: /usr/share/java/schema-registry (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:52,725] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:52,727] INFO Loading plugin from: /usr/share/java/confluent-telemetry (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:52,770] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-telemetry/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:52,771] INFO Loading plugin from: /usr/share/java/monitoring-interceptors (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:52,816] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/monitoring-interceptors/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:52,817] INFO Loading plugin from: /usr/share/java/confluent-control-center (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:53,854] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-control-center/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:53,856] INFO Loading plugin from: /usr/share/java/confluent-hub-client (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:53,925] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-hub-client/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:53,925] INFO Loading plugin from: /usr/share/java/confluent-common (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:53,946] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-common/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:53,947] INFO Loading plugin from: /usr/share/java/kafka-serde-tools (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:54,071] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-serde-tools/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:54,074] INFO Loading plugin from: /usr/share/java/rest-utils (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:54,380] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/rest-utils/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:54,383] INFO Loading plugin from: /usr/share/java/kafka (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:54,893] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:54,895] INFO Loading plugin from: /etc/kafka-connect/jars/confluentinc-kafka-connect-jdbc-10.8.0 (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:54,926] INFO Registered loader: PluginClassLoader{pluginLocation=file:/etc/kafka-connect/jars/confluentinc-kafka-connect-jdbc-10.8.0/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:55,252] INFO Loading plugin from: /etc/kafka-connect/jars/sinkfileconnector (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:55,298] INFO Registered loader: PluginClassLoader{pluginLocation=file:/etc/kafka-connect/jars/sinkfileconnector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:55,299] INFO Loading plugin from: /etc/kafka-connect/jars/debezium-connector-postgres (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:55,350] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter)
[2025-02-10 17:17:55,465] INFO Registered loader: PluginClassLoader{pluginLocation=file:/etc/kafka-connect/jars/debezium-connector-postgres/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:55,470] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:55,494] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:55,495] INFO Scanning plugins with ServiceLoaderScanner took 5043 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:17:55,501] INFO Loading plugin from: /usr/share/java/cp-base-new (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:01,878] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/cp-base-new/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:01,880] INFO Loading plugin from: /usr/share/java/acl (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:18,797] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/acl/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:18,798] INFO Loading plugin from: /usr/share/java/schema-registry (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:27,596] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:27,599] INFO Loading plugin from: /usr/share/java/confluent-telemetry (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:29,870] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-telemetry/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:29,871] INFO Loading plugin from: /usr/share/java/monitoring-interceptors (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:30,431] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/monitoring-interceptors/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:30,434] INFO Loading plugin from: /usr/share/java/confluent-control-center (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:45,313] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-control-center/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:45,317] INFO Loading plugin from: /usr/share/java/confluent-hub-client (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:46,243] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-hub-client/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:46,245] INFO Loading plugin from: /usr/share/java/confluent-common (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:46,269] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-common/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:46,269] INFO Loading plugin from: /usr/share/java/kafka-serde-tools (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:52,589] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-serde-tools/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:52,590] INFO Loading plugin from: /usr/share/java/rest-utils (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:54,681] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/rest-utils/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:54,681] INFO Loading plugin from: /usr/share/java/kafka (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:59,178] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:59,179] INFO Loading plugin from: /etc/kafka-connect/jars/confluentinc-kafka-connect-jdbc-10.8.0 (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:59,934] INFO Registered loader: PluginClassLoader{pluginLocation=file:/etc/kafka-connect/jars/confluentinc-kafka-connect-jdbc-10.8.0/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:59,945] INFO Loading plugin from: /etc/kafka-connect/jars/sinkfileconnector (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:59,964] INFO Registered loader: PluginClassLoader{pluginLocation=file:/etc/kafka-connect/jars/sinkfileconnector/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:18:59,964] INFO Loading plugin from: /etc/kafka-connect/jars/debezium-connector-postgres (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:19:00,289] INFO Registered loader: PluginClassLoader{pluginLocation=file:/etc/kafka-connect/jars/debezium-connector-postgres/} (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:19:00,291] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:19:16,038] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@1dbd16a6 (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:19:16,039] INFO Scanning plugins with ReflectionScanner took 80538 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner)
[2025-02-10 17:19:16,079] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/usr/share/java/acl/	io.confluent.connect.avro.AvroConverter	converter	undefined
file:/usr/share/java/confluent-control-center/	io.confluent.connect.avro.AvroConverter	converter	undefined
file:/usr/share/java/kafka-serde-tools/	io.confluent.connect.avro.AvroConverter	converter	undefined
classpath	io.confluent.connect.avro.AvroConverter	converter	undefined
file:/etc/kafka-connect/jars/confluentinc-kafka-connect-jdbc-10.8.0/	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.8.0
file:/etc/kafka-connect/jars/confluentinc-kafka-connect-jdbc-10.8.0/	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.8.0
file:/usr/share/java/acl/	io.confluent.connect.json.JsonSchemaConverter	converter	undefined
file:/usr/share/java/confluent-control-center/	io.confluent.connect.json.JsonSchemaConverter	converter	undefined
file:/usr/share/java/kafka-serde-tools/	io.confluent.connect.json.JsonSchemaConverter	converter	undefined
classpath	io.confluent.connect.json.JsonSchemaConverter	converter	undefined
file:/usr/share/java/acl/	io.confluent.connect.protobuf.ProtobufConverter	converter	undefined
file:/usr/share/java/confluent-control-center/	io.confluent.connect.protobuf.ProtobufConverter	converter	undefined
file:/usr/share/java/kafka-serde-tools/	io.confluent.connect.protobuf.ProtobufConverter	converter	undefined
classpath	io.confluent.connect.protobuf.ProtobufConverter	converter	undefined
file:/etc/kafka-connect/jars/debezium-connector-postgres/	io.debezium.connector.postgresql.transforms.DecodeLogicalDecodingMessageContent	transformation	3.0.6.Final
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins)
[2025-02-10 17:19:16,092] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,097] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,098] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,098] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,098] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,098] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,098] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'io.debezium.connector.postgresql.transforms.timescaledb.TimescaleDb' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,099] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'io.debezium.connector.postgresql.rest.DebeziumPostgresConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,100] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,105] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,105] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,105] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,105] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,105] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,106] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,106] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,106] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,106] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,106] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,106] INFO Added plugin 'io.debezium.connector.postgresql.transforms.DecodeLogicalDecodingMessageContent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'io.confluent.kafka.schemaregistry.client.config.provider.SchemaRegistryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,107] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,108] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,108] INFO Added plugin 'io.debezium.connector.postgresql.PostgresConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,108] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,108] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,108] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,108] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,132] INFO Added alias 'JsonSchema' to plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,132] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,132] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,132] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,133] INFO Added alias 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,133] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,133] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,134] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,134] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,134] INFO Added alias 'AvroConverter' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,134] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,134] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,135] INFO Added alias 'SchemaRegistryConfigProvider' to plugin 'io.confluent.kafka.schemaregistry.client.config.provider.SchemaRegistryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,135] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,135] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,135] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,136] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,136] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,136] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'FileStreamSinkConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'Protobuf' to plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'DebeziumPostgres' to plugin 'io.debezium.connector.postgresql.rest.DebeziumPostgresConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'FileStreamSourceConnector' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,137] INFO Added alias 'ConnectSecurityExtension' to plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'DebeziumPostgresConnectRestExtension' to plugin 'io.debezium.connector.postgresql.rest.DebeziumPostgresConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'Postgres' to plugin 'io.debezium.connector.postgresql.PostgresConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'DecodeLogicalDecodingMessageContent' to plugin 'io.debezium.connector.postgresql.transforms.DecodeLogicalDecodingMessageContent' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'TimescaleDb' to plugin 'io.debezium.connector.postgresql.transforms.timescaledb.TimescaleDb' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,138] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'ProtobufConverter' to plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'PostgresConnector' to plugin 'io.debezium.connector.postgresql.PostgresConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'JsonSchemaConverter' to plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,139] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,143] INFO Added alias 'SchemaRegistry' to plugin 'io.confluent.kafka.schemaregistry.client.config.provider.SchemaRegistryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader)
[2025-02-10 17:19:16,295] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [kafka-0:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = [file]
	config.storage.replication.factor = 1
	config.storage.topic = connect-config-storage
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = kafka-connect
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 60000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offset-storage
	plugin.discovery = hybrid_warn
	plugin.path = [/usr/share/java, /etc/kafka-connect/jars]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = localhost
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status-storage
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig)
[2025-02-10 17:19:16,296] WARN The worker has been configured with one or more internal converter properties ([internal.key.converter, schemas.enable, internal.value.converter, schemas.enable]). Support for these properties was deprecated in version 2.0 and removed in version 3.0, and specifying them will have no effect. Instead, an instance of the JsonConverter with schemas.enable set to false will be used. For more information, please visit https://kafka.apache.org/documentation/#upgrade and consult the upgrade notesfor the 3.0 release. (org.apache.kafka.connect.runtime.WorkerConfig)
[2025-02-10 17:19:16,301] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig)
[2025-02-10 17:19:16,315] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [kafka-0:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig)
[2025-02-10 17:19:16,568] INFO These configurations '[config.storage.topic, rest.advertised.host.name, group.id, status.storage.topic, plugin.path, internal.key.converter.schemas.enable, rest.port, config.storage.replication.factor, internal.key.converter, value.converter.schema.registry.url, status.storage.replication.factor, internal.value.converter.schemas.enable, internal.value.converter, offset.storage.replication.factor, config.providers.file.class, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig)
[2025-02-10 17:19:16,572] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:16,572] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:16,572] INFO Kafka startTimeMs: 1739207956568 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:17,887] INFO Kafka cluster ID: practicum (org.apache.kafka.connect.runtime.WorkerConfig)
[2025-02-10 17:19:17,889] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:17,914] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2025-02-10 17:19:17,916] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2025-02-10 17:19:17,917] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2025-02-10 17:19:17,928] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = localhost
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig)
[2025-02-10 17:19:17,956] INFO Logging initialized @89248ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
[2025-02-10 17:19:18,105] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:18,106] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:18,180] INFO jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 17.0.12+7-LTS (org.eclipse.jetty.server.Server)
[2025-02-10 17:19:18,254] INFO Started http_8083@16fd70f{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector)
[2025-02-10 17:19:18,255] INFO Started @89548ms (org.eclipse.jetty.server.Server)
[2025-02-10 17:19:18,320] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:18,320] INFO REST server listening at http://172.19.0.4:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:18,320] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:18,320] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:18,320] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:18,321] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy)
[2025-02-10 17:19:18,345] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig)
[2025-02-10 17:19:18,427] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:18,427] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:18,427] INFO Kafka startTimeMs: 1739207958427 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:18,453] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig)
[2025-02-10 17:19:18,456] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig)
[2025-02-10 17:19:18,575] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:18,750] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:18,752] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:18,752] INFO Kafka startTimeMs: 1739207958750 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:18,764] INFO Kafka Connect worker initialization took 88537ms (org.apache.kafka.connect.cli.AbstractConnectCli)
[2025-02-10 17:19:18,766] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect)
[2025-02-10 17:19:18,774] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:18,776] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:18,780] INFO Worker starting (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:18,780] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore)
[2025-02-10 17:19:18,781] INFO Starting KafkaBasedLog with topic connect-offset-storage reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-02-10 17:19:18,784] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [kafka-0:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-connect-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig)
[2025-02-10 17:19:18,801] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, group.id, status.storage.topic, plugin.path, internal.key.converter.schemas.enable, rest.port, config.storage.replication.factor, internal.key.converter, value.converter.schema.registry.url, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, internal.value.converter.schemas.enable, internal.value.converter, offset.storage.replication.factor, config.providers.file.class, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig)
[2025-02-10 17:19:18,801] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:18,801] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:18,801] INFO Kafka startTimeMs: 1739207958801 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:18,929] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:19,027] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [kafka-0:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-connect-offsets
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig)
[2025-02-10 17:19:19,139] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
[2025-02-10 17:19:19,140] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
[2025-02-10 17:19:19,144] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session)
[2025-02-10 17:19:19,149] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
[2025-02-10 17:19:19,298] INFO These configurations '[group.id, plugin.path, internal.key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, config.providers.file.class, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, rest.port, config.storage.replication.factor, internal.key.converter, value.converter.schema.registry.url, internal.value.converter.schemas.enable, internal.value.converter, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig)
[2025-02-10 17:19:19,298] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:19,298] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:19,298] INFO Kafka startTimeMs: 1739207959298 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:19,340] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [kafka-0:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-connect-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = kafka-connect
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig)
[2025-02-10 17:19:19,355] INFO [Producer clientId=kafka-connect-offsets] Cluster ID: practicum (org.apache.kafka.clients.Metadata)
[2025-02-10 17:19:19,408] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
[2025-02-10 17:19:19,591] INFO These configurations '[plugin.path, internal.key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, config.providers.file.class, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, rest.port, config.storage.replication.factor, internal.key.converter, value.converter.schema.registry.url, internal.value.converter.schemas.enable, internal.value.converter, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig)
[2025-02-10 17:19:19,591] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:19,595] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:19,595] INFO Kafka startTimeMs: 1739207959591 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:19,635] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Cluster ID: practicum (org.apache.kafka.clients.Metadata)
[2025-02-10 17:19:19,654] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Assigned to partition(s): connect-offset-storage-6, connect-offset-storage-14, connect-offset-storage-22, connect-offset-storage-4, connect-offset-storage-3, connect-offset-storage-20, connect-offset-storage-24, connect-offset-storage-2, connect-offset-storage-10, connect-offset-storage-1, connect-offset-storage-23, connect-offset-storage-7, connect-offset-storage-19, connect-offset-storage-5, connect-offset-storage-17, connect-offset-storage-15, connect-offset-storage-13, connect-offset-storage-21, connect-offset-storage-12, connect-offset-storage-11, connect-offset-storage-18, connect-offset-storage-9, connect-offset-storage-0, connect-offset-storage-8, connect-offset-storage-16 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer)
[2025-02-10 17:19:19,659] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,660] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,662] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Seeking to earliest offset of partition connect-offset-storage-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,859] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,860] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,861] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,861] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,861] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,861] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,861] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,865] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,872] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,873] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,873] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,873] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,874] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,874] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,874] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,874] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,874] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,896] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-0:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,896] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-0:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,896] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-0:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,898] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-0:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,898] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-0:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,898] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-0:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,898] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-0:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:19,898] INFO [Consumer clientId=kafka-connect-offsets, groupId=kafka-connect] Resetting offset for partition connect-offset-storage-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-0:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,355] INFO Finished reading KafkaBasedLog for topic connect-offset-storage (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-02-10 17:19:20,355] INFO Started KafkaBasedLog for topic connect-offset-storage (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-02-10 17:19:20,355] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore)
[2025-02-10 17:19:20,362] INFO Worker started (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:20,363] INFO Starting KafkaBasedLog with topic connect-status-storage reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-02-10 17:19:20,392] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [kafka-0:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-connect-statuses
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig)
[2025-02-10 17:19:20,393] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
[2025-02-10 17:19:20,417] INFO These configurations '[group.id, plugin.path, internal.key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, config.providers.file.class, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, rest.port, config.storage.replication.factor, internal.key.converter, value.converter.schema.registry.url, internal.value.converter.schemas.enable, internal.value.converter, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig)
[2025-02-10 17:19:20,417] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,418] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,420] INFO Kafka startTimeMs: 1739207960417 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,422] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [kafka-0:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-connect-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = kafka-connect
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig)
[2025-02-10 17:19:20,430] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
[2025-02-10 17:19:20,440] INFO [Producer clientId=kafka-connect-statuses] Cluster ID: practicum (org.apache.kafka.clients.Metadata)
[2025-02-10 17:19:20,462] INFO These configurations '[plugin.path, internal.key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, config.providers.file.class, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, rest.port, config.storage.replication.factor, internal.key.converter, value.converter.schema.registry.url, internal.value.converter.schemas.enable, internal.value.converter, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig)
[2025-02-10 17:19:20,467] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,467] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,467] INFO Kafka startTimeMs: 1739207960465 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,486] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Cluster ID: practicum (org.apache.kafka.clients.Metadata)
[2025-02-10 17:19:20,499] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Assigned to partition(s): connect-status-storage-4, connect-status-storage-1, connect-status-storage-3, connect-status-storage-2, connect-status-storage-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer)
[2025-02-10 17:19:20,499] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Seeking to earliest offset of partition connect-status-storage-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,499] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Seeking to earliest offset of partition connect-status-storage-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,500] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Seeking to earliest offset of partition connect-status-storage-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,500] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Seeking to earliest offset of partition connect-status-storage-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,500] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Seeking to earliest offset of partition connect-status-storage-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,617] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Resetting offset for partition connect-status-storage-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,620] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Resetting offset for partition connect-status-storage-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,635] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Resetting offset for partition connect-status-storage-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-0:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,641] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Resetting offset for partition connect-status-storage-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,641] INFO [Consumer clientId=kafka-connect-statuses, groupId=kafka-connect] Resetting offset for partition connect-status-storage-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-1:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:20,743] INFO Finished reading KafkaBasedLog for topic connect-status-storage (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-02-10 17:19:20,743] INFO Started KafkaBasedLog for topic connect-status-storage (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-02-10 17:19:20,770] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore)
[2025-02-10 17:19:20,770] INFO Starting KafkaBasedLog with topic connect-config-storage reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-02-10 17:19:20,843] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [kafka-0:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-connect-configs
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig)
[2025-02-10 17:19:20,843] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
[2025-02-10 17:19:20,883] INFO These configurations '[group.id, plugin.path, internal.key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, config.providers.file.class, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, rest.port, config.storage.replication.factor, internal.key.converter, value.converter.schema.registry.url, internal.value.converter.schemas.enable, internal.value.converter, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig)
[2025-02-10 17:19:20,884] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,885] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,886] INFO Kafka startTimeMs: 1739207960884 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,896] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [kafka-0:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = kafka-connect-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = kafka-connect
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig)
[2025-02-10 17:19:20,901] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
[2025-02-10 17:19:20,927] INFO [Producer clientId=kafka-connect-configs] Cluster ID: practicum (org.apache.kafka.clients.Metadata)
[2025-02-10 17:19:20,991] INFO These configurations '[plugin.path, internal.key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, config.providers.file.class, offset.storage.topic, value.converter, key.converter, config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, status.storage.topic, rest.port, config.storage.replication.factor, internal.key.converter, value.converter.schema.registry.url, internal.value.converter.schemas.enable, internal.value.converter, offset.storage.replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig)
[2025-02-10 17:19:20,991] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,991] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:20,991] INFO Kafka startTimeMs: 1739207960991 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:21,022] INFO [Consumer clientId=kafka-connect-configs, groupId=kafka-connect] Cluster ID: practicum (org.apache.kafka.clients.Metadata)
[2025-02-10 17:19:21,039] INFO [Consumer clientId=kafka-connect-configs, groupId=kafka-connect] Assigned to partition(s): connect-config-storage-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer)
[2025-02-10 17:19:21,039] INFO [Consumer clientId=kafka-connect-configs, groupId=kafka-connect] Seeking to earliest offset of partition connect-config-storage-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:21,178] INFO [Consumer clientId=kafka-connect-configs, groupId=kafka-connect] Resetting offset for partition connect-config-storage-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka-2:9092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState)
[2025-02-10 17:19:21,268] INFO Finished reading KafkaBasedLog for topic connect-config-storage (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-02-10 17:19:21,269] INFO Started KafkaBasedLog for topic connect-config-storage (org.apache.kafka.connect.util.KafkaBasedLog)
[2025-02-10 17:19:21,269] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore)
[2025-02-10 17:19:21,269] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:21,306] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Cluster ID: practicum (org.apache.kafka.clients.Metadata)
[2025-02-10 17:19:21,308] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Discovered group coordinator kafka-2:9092 (id: 2147483645 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[2025-02-10 17:19:21,366] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[2025-02-10 17:19:21,366] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[2025-02-10 17:19:21,409] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[2025-02-10 17:19:22,039] INFO Started o.e.j.s.ServletContextHandler@69633a45{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
[2025-02-10 17:19:22,039] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:22,039] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect)
[2025-02-10 17:19:23,901] INFO [0:0:0:0:0:0:0:1] - - [10/Feb/2025:17:19:23 +0000] "GET /connectors HTTP/1.1" 200 16 "-" "curl/7.61.1" 400 (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:24,416] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Successfully joined group with generation Generation{generationId=1, memberId='connect-localhost:8083-2a7b9279-d90b-4daf-87f3-3994b767f5ab', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[2025-02-10 17:19:24,494] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Successfully synced group in generation Generation{generationId=1, memberId='connect-localhost:8083-2a7b9279-d90b-4daf-87f3-3994b767f5ab', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator)
[2025-02-10 17:19:24,498] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-localhost:8083-2a7b9279-d90b-4daf-87f3-3994b767f5ab', leaderUrl='http://localhost:8083/', offset=20, connectorIds=[pg-connector], taskIds=[pg-connector-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:24,503] WARN [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:24,504] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Current config state offset -1 is behind group assignment 20, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:24,554] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Finished reading to end of log and updated config snapshot, new config log offset: 20 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:24,555] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Starting connectors and tasks using config offset 20 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:24,559] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Starting task pg-connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:24,561] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Starting connector pg-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:24,576] INFO Creating connector pg-connector of type io.debezium.connector.postgresql.PostgresConnector (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:24,580] INFO Creating task pg-connector-0 (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:24,589] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = pg-connector
	predicates = []
	tasks.max = 1
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig)
[2025-02-10 17:19:24,593] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig)
[2025-02-10 17:19:24,605] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = pg-connector
	predicates = []
	tasks.max = 1
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[2025-02-10 17:19:24,611] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[2025-02-10 17:19:24,630] INFO TaskConfig values: 
	task.class = class io.debezium.connector.postgresql.PostgresConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig)
[2025-02-10 17:19:24,632] INFO EnrichedSourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = -1
	topic.creation.default.replication.factor = -1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig$EnrichedSourceConnectorConfig)
[2025-02-10 17:19:24,636] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = -1
	topic.creation.default.replication.factor = -1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[2025-02-10 17:19:24,656] INFO Instantiated task pg-connector-0 with version 3.0.6.Final of type io.debezium.connector.postgresql.PostgresConnectorTask (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:24,661] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig)
[2025-02-10 17:19:24,661] INFO Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task pg-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:24,662] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig)
[2025-02-10 17:19:24,662] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task pg-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:24,662] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task pg-connector-0 using the worker config (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:24,681] INFO Instantiated connector pg-connector with version 3.0.6.Final of type class io.debezium.connector.postgresql.PostgresConnector (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:24,686] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig)
[2025-02-10 17:19:24,691] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[2025-02-10 17:19:24,694] INFO Finished creating connector pg-connector (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:24,695] INFO EnrichedSourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = -1
	topic.creation.default.replication.factor = -1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig$EnrichedSourceConnectorConfig)
[2025-02-10 17:19:24,701] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = -1
	topic.creation.default.replication.factor = -1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[2025-02-10 17:19:24,734] WARN The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState)
[2025-02-10 17:19:24,744] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.transforms.ExtractNewRecordState} (org.apache.kafka.connect.runtime.Worker)
[2025-02-10 17:19:24,749] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [kafka-0:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-pg-connector-0
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig)
[2025-02-10 17:19:24,750] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector)
[2025-02-10 17:19:24,779] INFO These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig)
[2025-02-10 17:19:24,779] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:24,779] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:24,781] INFO Kafka startTimeMs: 1739207964779 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:24,799] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [kafka-0:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connector-adminclient-pg-connector-0
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig)
[2025-02-10 17:19:24,800] INFO [Producer clientId=connector-producer-pg-connector-0] Cluster ID: practicum (org.apache.kafka.clients.Metadata)
[2025-02-10 17:19:24,826] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, rest.advertised.host.name, group.id, status.storage.topic, plugin.path, internal.key.converter.schemas.enable, rest.port, config.storage.replication.factor, internal.key.converter, value.converter.schema.registry.url, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, internal.value.converter.schemas.enable, internal.value.converter, offset.storage.replication.factor, config.providers.file.class, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig)
[2025-02-10 17:19:24,848] INFO Kafka version: 7.7.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:24,848] INFO Kafka commitId: 91d86f33092378c89731b4a9cf1ce5db831a2b07 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:24,848] INFO Kafka startTimeMs: 1739207964826 (org.apache.kafka.common.utils.AppInfoParser)
[2025-02-10 17:19:24,943] INFO [Worker clientId=connect-localhost:8083, groupId=kafka-connect] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder)
[2025-02-10 17:19:24,964] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig)
[2025-02-10 17:19:24,968] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[2025-02-10 17:19:24,973] INFO EnrichedSourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = -1
	topic.creation.default.replication.factor = -1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig$EnrichedSourceConnectorConfig)
[2025-02-10 17:19:24,980] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.postgresql.PostgresConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = pg-connector
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.default.exclude = []
	topic.creation.default.include = [.*]
	topic.creation.default.partitions = -1
	topic.creation.default.replication.factor = -1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = false
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig)
[2025-02-10 17:19:25,084] INFO Starting PostgresConnectorTask with configuration:
   connector.class = io.debezium.connector.postgresql.PostgresConnector
   database.user = postgres-user
   database.dbname = customers
   transforms.unwrap.delete.handling.mode = rewrite
   topic.creation.default.partitions = -1
   transforms = unwrap
   database.server.name = customers
   database.port = 5432
   table.whitelist = public.users
   topic.creation.enable = true
   topic.prefix = customers
   task.class = io.debezium.connector.postgresql.PostgresConnectorTask
   database.hostname = postgres
   database.password = ********
   transforms.unwrap.drop.tombstones = false
   topic.creation.default.replication.factor = -1
   name = pg-connector
   transforms.unwrap.type = io.debezium.transforms.ExtractNewRecordState
   skipped.operations = none
 (io.debezium.connector.common.BaseSourceTask)
[2025-02-10 17:19:25,095] INFO Loading the custom source info struct maker plugin: io.debezium.connector.postgresql.PostgresSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig)
[2025-02-10 17:19:25,131] INFO Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy (io.debezium.config.CommonConnectorConfig)
[2025-02-10 17:19:25,421] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection)
[2025-02-10 17:19:25,648] WARN Type [oid:13529, name:_pg_user_mappings] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,650] WARN Type [oid:13203, name:cardinal_number] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,650] WARN Type [oid:13206, name:character_data] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,650] WARN Type [oid:13208, name:sql_identifier] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,651] WARN Type [oid:13214, name:time_stamp] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,651] WARN Type [oid:13216, name:yes_or_no] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,815] INFO Found previous partition offset PostgresPartition [sourcePartition={server=customers}]: {lsn=27306320, txId=736, ts_usec=1739162791781450} (io.debezium.connector.common.BaseSourceTask)
[2025-02-10 17:19:25,936] WARN Type [oid:13529, name:_pg_user_mappings] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,936] WARN Type [oid:13203, name:cardinal_number] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,936] WARN Type [oid:13206, name:character_data] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,936] WARN Type [oid:13208, name:sql_identifier] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,936] WARN Type [oid:13214, name:time_stamp] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:25,936] WARN Type [oid:13216, name:yes_or_no] is already mapped (io.debezium.connector.postgresql.TypeRegistry)
[2025-02-10 17:19:26,021] INFO Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/1A0A950}, catalogXmin=736] (io.debezium.connector.postgresql.connection.PostgresConnection)
[2025-02-10 17:19:26,086] INFO Found previous offset PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='customers'db='customers', lsn=LSN{0/1A0A950}, txId=736, timestamp=2025-02-10T04:46:31.781450Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]] (io.debezium.connector.postgresql.PostgresConnectorTask)
[2025-02-10 17:19:26,146] INFO user 'postgres-user' connected to database 'customers' on PostgreSQL 16.4 (Debian 16.4-1.pgdg110+2) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit with roles:
	role 'pg_read_all_settings' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_database_owner' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_stat_scan_tables' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_checkpoint' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_write_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_use_reserved_connections' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'postgres-user' [superuser: true, replication: true, inherit: true, create role: true, create db: true, can log in: true]
	role 'pg_read_all_data' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_write_all_data' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_monitor' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_read_server_files' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_create_subscription' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_execute_server_program' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_read_all_stats' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false]
	role 'pg_signal_backend' [superuser: false, replication: false, inherit: true, create role: false, create db: false, can log in: false] (io.debezium.connector.postgresql.PostgresConnectorTask)
[2025-02-10 17:19:26,151] INFO Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/1A0A950}, catalogXmin=736] (io.debezium.connector.postgresql.connection.PostgresConnection)
[2025-02-10 17:19:26,188] INFO Requested thread factory for component PostgresConnector, id = customers named = SignalProcessor (io.debezium.util.Threads)
[2025-02-10 17:19:26,246] INFO Requested thread factory for component PostgresConnector, id = customers named = change-event-source-coordinator (io.debezium.util.Threads)
[2025-02-10 17:19:26,246] INFO Requested thread factory for component PostgresConnector, id = customers named = blocking-snapshot (io.debezium.util.Threads)
[2025-02-10 17:19:26,267] INFO Creating thread debezium-postgresconnector-customers-change-event-source-coordinator (io.debezium.util.Threads)
[2025-02-10 17:19:26,270] INFO WorkerSourceTask{id=pg-connector-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask)
[2025-02-10 17:19:26,296] INFO Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator)
[2025-02-10 17:19:26,300] INFO Context created (io.debezium.pipeline.ChangeEventSourceCoordinator)
[2025-02-10 17:19:26,327] INFO A previous offset indicating a completed snapshot has been found. (io.debezium.connector.postgresql.PostgresSnapshotChangeEventSource)
[2025-02-10 17:19:26,328] INFO According to the connector configuration no snapshot will be executed (io.debezium.connector.postgresql.PostgresSnapshotChangeEventSource)
[2025-02-10 17:19:26,341] INFO Snapshot ended with SnapshotResult [status=SKIPPED, offset=PostgresOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.postgresql.Source:STRUCT}, sourceInfo=source_info[server='customers'db='customers', lsn=LSN{0/1A0A950}, txId=736, timestamp=2025-02-10T04:46:31.781450Z, snapshot=FALSE, schema=, table=], lastSnapshotRecord=true, lastCompletelyProcessedLsn=null, lastCommitLsn=null, streamingStoppingLsn=null, transactionContext=TransactionContext [currentTransactionId=null, perTableEventCount={}, totalEventCount=0], incrementalSnapshotContext=IncrementalSnapshotContext [windowOpened=false, chunkEndPosition=null, dataCollectionsToSnapshot=[], lastEventKeySent=null, maximumKey=null]]] (io.debezium.pipeline.ChangeEventSourceCoordinator)
[2025-02-10 17:19:26,357] INFO Connected metrics set to 'true' (io.debezium.pipeline.ChangeEventSourceCoordinator)
[2025-02-10 17:19:26,597] INFO REPLICA IDENTITY for 'public.users' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns (io.debezium.connector.postgresql.PostgresSchema)
[2025-02-10 17:19:26,658] INFO SignalProcessor started. Scheduling it every 5000ms (io.debezium.pipeline.signal.SignalProcessor)
[2025-02-10 17:19:26,660] INFO Creating thread debezium-postgresconnector-customers-SignalProcessor (io.debezium.util.Threads)
[2025-02-10 17:19:26,660] INFO Starting streaming (io.debezium.pipeline.ChangeEventSourceCoordinator)
[2025-02-10 17:19:26,661] INFO Retrieved latest position from stored offset 'LSN{0/1A0A950}' (io.debezium.connector.postgresql.PostgresStreamingChangeEventSource)
[2025-02-10 17:19:26,664] INFO Looking for WAL restart position for last commit LSN 'null' and last change LSN 'LSN{0/1A0A950}' (io.debezium.connector.postgresql.connection.WalPositionLocator)
[2025-02-10 17:19:26,736] INFO Obtained valid replication slot ReplicationSlot [active=false, latestFlushedLsn=LSN{0/1A0A950}, catalogXmin=736] (io.debezium.connector.postgresql.connection.PostgresConnection)
[2025-02-10 17:19:26,741] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection)
[2025-02-10 17:19:26,876] INFO Requested thread factory for component PostgresConnector, id = customers named = keep-alive (io.debezium.util.Threads)
[2025-02-10 17:19:26,878] INFO Creating thread debezium-postgresconnector-customers-keep-alive (io.debezium.util.Threads)
[2025-02-10 17:19:27,018] INFO REPLICA IDENTITY for 'public.users' is 'DEFAULT'; UPDATE and DELETE events will contain previous values only for PK columns (io.debezium.connector.postgresql.PostgresSchema)
[2025-02-10 17:19:27,023] INFO Processing messages (io.debezium.connector.postgresql.PostgresStreamingChangeEventSource)
[2025-02-10 17:19:29,149] INFO [0:0:0:0:0:0:0:1] - - [10/Feb/2025:17:19:29 +0000] "GET /connectors HTTP/1.1" 200 16 "-" "curl/7.61.1" 25 (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:34,322] INFO [0:0:0:0:0:0:0:1] - - [10/Feb/2025:17:19:34 +0000] "GET /connectors HTTP/1.1" 200 16 "-" "curl/7.61.1" 10 (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:39,499] INFO [0:0:0:0:0:0:0:1] - - [10/Feb/2025:17:19:39 +0000] "GET /connectors HTTP/1.1" 200 16 "-" "curl/7.61.1" 8 (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:44,708] INFO [0:0:0:0:0:0:0:1] - - [10/Feb/2025:17:19:44 +0000] "GET /connectors HTTP/1.1" 200 16 "-" "curl/7.61.1" 15 (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:49,879] INFO [0:0:0:0:0:0:0:1] - - [10/Feb/2025:17:19:49 +0000] "GET /connectors HTTP/1.1" 200 16 "-" "curl/7.61.1" 5 (org.apache.kafka.connect.runtime.rest.RestServer)
[2025-02-10 17:19:55,046] INFO [0:0:0:0:0:0:0:1] - - [10/Feb/2025:17:19:55 +0000] "GET /connectors HTTP/1.1" 200 16 "-" "curl/7.61.1" 12 (org.apache.kafka.connect.runtime.rest.RestServer)